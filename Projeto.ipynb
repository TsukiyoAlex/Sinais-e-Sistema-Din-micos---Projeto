{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Sinais e Sistemas Dinâmicos 2019.1\n",
    "\n",
    "**Professor:** Derzu Omaia\n",
    "\n",
    "**Grupo:**\n",
    "- Aléxandros Augustus\n",
    "- Ana Maria da Silva\n",
    "- Gabriel Formiga\n",
    "- Johan Kevin de Freitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando ferramentas\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Aplicação da Transformada de Fourier Bidimensional\n",
    "O primeiro passo é extrair as imagens dos arquivos como matrizes numéricas para que possamos aplicar a transformada de Fourier bidimensional e então faremos um shift para concentrar o resultado da transformada no centro da imagem para que seja mais fácil utilizá-lo. Ao extrair estamos logo separando os futuros conjuntos de treinamento e teste onde será utilizado KNN. As imagens selecionadas para teste são uma imagem aleatória de cada pessoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "360\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "faces_test = []\n",
    "faces_train = []\n",
    "\n",
    "#extraindo fotos como matrizes numéricas\n",
    "n = random.randint(0,9)\n",
    "for i in range(40):\n",
    "    for j in range(10):\n",
    "        if j == n:\n",
    "            faces_test.append(np.array(cv2.imread(f'orl_faces/s{i+1}/{j+1}.pgm',0)))\n",
    "        else:\n",
    "            faces_train.append(np.array(cv2.imread(f'orl_faces/s{i+1}/{j+1}.pgm',0)))\n",
    "print(n)\n",
    "print(len(faces_train))\n",
    "print(len(faces_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#aplicando transformada de Fourier bidimensional e o shift\n",
    "faces_trainfft = [np.fft.fft2(n) for n in faces_train]\n",
    "faces_testfft = [np.fft.fft2(n) for n in faces_test]\n",
    "faces_trainshift = [np.fft.fftshift(n) for n in faces_trainfft]\n",
    "faces_testshift = [np.fft.fftshift(n) for n in faces_testfft]\n",
    "    \n",
    "x = random.randint(0,len(faces_trainshift)-1)\n",
    "y = random.randint(0,len(faces_testshift)-1)\n",
    "\n",
    "#exibindo elemento qualquer das imagens extraídas e transformadas\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.abs(faces_trainshift[x]),cmap='gray')\n",
    "plt.title(f'Elemento {x+1}')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.abs(faces_testshift[y]),cmap='gray')\n",
    "plt.title(f'Elemento {y+1}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora queremos diminuir o tamanho da imagem para os tamanhos 2x2 pixels e 50x50 pixels, para isso fazemos uma função que\n",
    "encontra o pixel central e a partir desse pixel retorna apenas a região da imagem com o tamanho a que desejamos reduzir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que reduz a imagem para o tamanho dxd\n",
    "def crop(d,img):\n",
    "    x = 92//2\n",
    "    y = 112//2\n",
    "    r = d//2\n",
    "    \n",
    "    return img[x-r:x+r,y-r:y+r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 4)\n",
      "(40, 4)\n",
      "(360, 2500)\n",
      "(40, 2500)\n"
     ]
    }
   ],
   "source": [
    "#aplicando redução em todas as imagens da transformada de fourier bidimensional com shift\n",
    "faces2_train = [np.array(crop(2,img)).flatten() for img in faces_trainshift]\n",
    "faces2_test = [np.array(crop(2,img)).flatten() for img in faces_testshift]\n",
    "faces50_train = [np.array(crop(50,img)).flatten() for img in faces_trainshift]\n",
    "faces50_test = [np.array(crop(50,img)).flatten() for img in faces_testshift]\n",
    "\n",
    "print(np.array(faces2_train).shape)\n",
    "print(np.array(faces2_test).shape)\n",
    "print(np.array(faces50_train).shape)\n",
    "print(np.array(faces50_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 400)\n",
      "(40, 400)\n",
      "(360, 900)\n",
      "(40, 900)\n"
     ]
    }
   ],
   "source": [
    "#aplicando redução em todas as imagens da transformada de fourier bidimensional com shift\n",
    "faces20_train = [np.array(crop(20,img)).flatten() for img in faces_trainshift]\n",
    "faces20_test = [np.array(crop(20,img)).flatten() for img in faces_testshift]\n",
    "faces30_train = [np.array(crop(30,img)).flatten() for img in faces_trainshift]\n",
    "faces30_test = [np.array(crop(30,img)).flatten() for img in faces_testshift]\n",
    "\n",
    "print(np.array(faces20_train).shape)\n",
    "print(np.array(faces20_test).shape)\n",
    "print(np.array(faces30_train).shape)\n",
    "print(np.array(faces30_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após gerarmos as imagens reduzidas podemos finalmente guardar esses resultados nas bases de dados que desejamos utilizar\n",
    "para aplicar o KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2x2 real e imaginário\n",
    "f2r_train = []\n",
    "f2r_test = []\n",
    "f2i_train = []\n",
    "f2i_test = []\n",
    "\n",
    "for n in range(360):\n",
    "    f2r_train.append(np.array(faces2_train[n]).real)\n",
    "    f2i_train.append(np.array(faces2_train[n]).imag)\n",
    "\n",
    "for n in range(40):\n",
    "    f2r_test.append(np.array(faces2_test[n]).real)\n",
    "    f2i_test.append(np.array(faces2_test[n]).imag)\n",
    "    \n",
    "#50x50 real e imaginário\n",
    "f50r_train = []\n",
    "f50r_test = []\n",
    "f50i_train = []\n",
    "f50i_test = []\n",
    "\n",
    "for n in range(360):\n",
    "    f50r_train.append(np.array(faces50_train[n]).real)\n",
    "    f50i_train.append(np.array(faces50_train[n]).imag)\n",
    "    \n",
    "for n in range(40):\n",
    "    f50r_test.append(np.array(faces50_test[n]).real)\n",
    "    f50i_test.append(np.array(faces50_test[n]).imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20x20 real e imaginário\n",
    "f20r_train = []\n",
    "f20r_test = []\n",
    "f20i_train = []\n",
    "f20i_test = []\n",
    "\n",
    "for n in range(360):\n",
    "    f20r_train.append(np.array(faces20_train[n]).real)\n",
    "    f20i_train.append(np.array(faces20_train[n]).imag)\n",
    "\n",
    "for n in range(40):\n",
    "    f20r_test.append(np.array(faces20_test[n]).real)\n",
    "    f20i_test.append(np.array(faces20_test[n]).imag)\n",
    "    \n",
    "#30x30 real e imaginário\n",
    "f30r_train = []\n",
    "f30r_test = []\n",
    "f30i_train = []\n",
    "f30i_test = []\n",
    "\n",
    "for n in range(360):\n",
    "    f30r_train.append(np.array(faces30_train[n]).real)\n",
    "    f30i_train.append(np.array(faces30_train[n]).imag)\n",
    "    \n",
    "for n in range(40):\n",
    "    f30r_test.append(np.array(faces30_test[n]).real)\n",
    "    f30i_test.append(np.array(faces30_test[n]).imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinando módulos real e imaginário em uma base única\n",
    "f2ri_train = []\n",
    "f2ri_test = []\n",
    "f50ri_train = []\n",
    "f50ri_test = []\n",
    "\n",
    "for x in range(360):\n",
    "    f2ri_train.append([])\n",
    "    f50ri_train.append([])\n",
    "    for y1 in range(4):\n",
    "        f2ri_train[x].append(f2r_train[x][y1]+f2i_train[x][y1])\n",
    "    for y2 in range(2500):\n",
    "        f50ri_train[x].append(f50r_train[x][y2]+f50i_train[x][y2])\n",
    "        \n",
    "for x in range(40):\n",
    "    f2ri_test.append([])\n",
    "    f50ri_test.append([])\n",
    "    for y1 in range(4):\n",
    "        f2ri_test[x].append(f2r_test[x][y1]+f2i_test[x][y1])\n",
    "    for y2 in range(2500):\n",
    "        f50ri_test[x].append(f50r_test[x][y2]+f50i_test[x][y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinando módulos real e imaginário em uma base única\n",
    "f20ri_train = []\n",
    "f20ri_test = []\n",
    "f30ri_train = []\n",
    "f30ri_test = []\n",
    "\n",
    "for x in range(360):\n",
    "    f20ri_train.append([])\n",
    "    f30ri_train.append([])\n",
    "    for y1 in range(400):\n",
    "        f20ri_train[x].append(f20r_train[x][y1]+f20i_train[x][y1])\n",
    "    for y2 in range(900):\n",
    "        f30ri_train[x].append(f30r_train[x][y2]+f30i_train[x][y2])\n",
    "        \n",
    "for x in range(40):\n",
    "    f20ri_test.append([])\n",
    "    f30ri_test.append([])\n",
    "    for y1 in range(400):\n",
    "        f20ri_test[x].append(f20r_test[x][y1]+f20i_test[x][y1])\n",
    "    for y2 in range(900):\n",
    "        f30ri_test[x].append(f30r_test[x][y2]+f30i_test[x][y2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Utilização de KNN\n",
    "### 2.1 Preparação das bases\n",
    "Agora que temos os dados necessários precisamos organizá-los em um conjunto com os *labels* de cada imagem para que a função de KNN seja capaz de classificá-las, para isso vamos transformar cada pixel das imagens como uma coluna e adicionamos esses dados a um *data frame* do pandas as matrizes com os respectivos *labels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gerando array de labels\n",
    "labels_train = [(x+1) for x in range(40) for y in range(9)]\n",
    "labels_test = [(x+1) for x in range(40)]\n",
    "\n",
    "#adicionando os dados com labels aos respectivos data frames\n",
    "datareal2_train = {'Pessoa':labels_train,'Imagem':f2r_train}\n",
    "real2_train = pd.DataFrame(data=datareal2_train)\n",
    "datareal2_test = {'Pessoa':labels_test,'Imagem':f2r_test}\n",
    "real2_test = pd.DataFrame(data=datareal2_test)\n",
    "\n",
    "dataimag2_train = {'Pessoa':labels_train,'Imagem':f2i_train}\n",
    "imag2_train = pd.DataFrame(data=dataimag2_train)\n",
    "dataimag2_test = {'Pessoa':labels_test,'Imagem':f2i_test}\n",
    "imag2_test = pd.DataFrame(data=dataimag2_test)\n",
    "\n",
    "datari2_train = {'Pessoa':labels_train,'Imagem':f2ri_train}\n",
    "ri2_train = pd.DataFrame(data=datari2_train)\n",
    "datari2_test = {'Pessoa':labels_test,'Imagem':f2ri_test}\n",
    "ri2_test = pd.DataFrame(data=datari2_test)\n",
    "\n",
    "aux2_train = [np.concatenate((real2_train['Imagem'][n],imag2_train['Imagem'][n])) for n in range(360)]\n",
    "datafull2_train = {'Pessoa':labels_train,'Imagem':aux2_train}\n",
    "full2_train = pd.DataFrame(data=datafull2_train)\n",
    "aux2_test = [np.concatenate((real2_test['Imagem'][n],imag2_test['Imagem'][n])) for n in range(40)]\n",
    "datafull2_test = {'Pessoa':labels_test,'Imagem':aux2_test}\n",
    "full2_test = pd.DataFrame(data=datafull2_test)\n",
    "\n",
    "conc2_train = pd.concat([real2_train,imag2_train],ignore_index=True)\n",
    "conc2_test = pd.concat([real2_test, imag2_test],ignore_index=True)\n",
    "\n",
    "datareal50_train = {'Pessoa':labels_train,'Imagem':f50r_train}\n",
    "real50_train = pd.DataFrame(data=datareal50_train)\n",
    "datareal50_test = {'Pessoa':labels_test,'Imagem':f50r_test}\n",
    "real50_test = pd.DataFrame(data=datareal50_test)\n",
    "                  \n",
    "dataimag50_train = {'Pessoa':labels_train,'Imagem':f50i_train}\n",
    "imag50_train = pd.DataFrame(data=dataimag50_train)\n",
    "dataimag50_test = {'Pessoa':labels_test,'Imagem':f50i_test}\n",
    "imag50_test = pd.DataFrame(data=dataimag50_test)\n",
    "                  \n",
    "datari50_train = {'Pessoa':labels_train,'Imagem':f50ri_train}\n",
    "ri50_train = pd.DataFrame(data=datari50_train)\n",
    "datari50_test = {'Pessoa':labels_test,'Imagem':f50ri_test}\n",
    "ri50_test = pd.DataFrame(data=datari50_test)\n",
    "\n",
    "aux50_train = [np.concatenate((real50_train['Imagem'][n],imag50_train['Imagem'][n])) for n in range(360)]\n",
    "datafull50_train = {'Pessoa':labels_train,'Imagem':aux50_train}\n",
    "full50_train = pd.DataFrame(data=datafull50_train)\n",
    "aux50_test = [np.concatenate((real50_test['Imagem'][n],imag50_test['Imagem'][n])) for n in range(40)]\n",
    "datafull50_test = {'Pessoa':labels_test,'Imagem':aux50_test}\n",
    "full50_test = pd.DataFrame(data=datafull50_test)\n",
    "\n",
    "conc50_train = pd.concat([real50_train,imag50_train],ignore_index=True)\n",
    "conc50_test = pd.concat([real50_test, imag50_test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerando array de labels\n",
    "labels_train = [(x+1) for x in range(40) for y in range(9)]\n",
    "labels_test = [(x+1) for x in range(40)]\n",
    "\n",
    "#adicionando os dados com labels aos respectivos data frames\n",
    "datareal20_train = {'Pessoa':labels_train,'Imagem':f20r_train}\n",
    "real20_train = pd.DataFrame(data=datareal20_train)\n",
    "datareal20_test = {'Pessoa':labels_test,'Imagem':f20r_test}\n",
    "real20_test = pd.DataFrame(data=datareal20_test)\n",
    "\n",
    "dataimag20_train = {'Pessoa':labels_train,'Imagem':f20i_train}\n",
    "imag20_train = pd.DataFrame(data=dataimag20_train)\n",
    "dataimag20_test = {'Pessoa':labels_test,'Imagem':f20i_test}\n",
    "imag20_test = pd.DataFrame(data=dataimag20_test)\n",
    "\n",
    "datari20_train = {'Pessoa':labels_train,'Imagem':f20ri_train}\n",
    "ri20_train = pd.DataFrame(data=datari20_train)\n",
    "datari20_test = {'Pessoa':labels_test,'Imagem':f20ri_test}\n",
    "ri20_test = pd.DataFrame(data=datari20_test)\n",
    "\n",
    "aux20_train = [np.concatenate((real20_train['Imagem'][n],imag20_train['Imagem'][n])) for n in range(360)]\n",
    "datafull20_train = {'Pessoa':labels_train,'Imagem':aux20_train}\n",
    "full20_train = pd.DataFrame(data=datafull20_train)\n",
    "aux20_test = [np.concatenate((real20_test['Imagem'][n],imag20_test['Imagem'][n])) for n in range(40)]\n",
    "datafull20_test = {'Pessoa':labels_test,'Imagem':aux20_test}\n",
    "full20_test = pd.DataFrame(data=datafull20_test)\n",
    "\n",
    "conc20_train = pd.concat([real20_train,imag20_train],ignore_index=True)\n",
    "conc20_test = pd.concat([real20_test, imag20_test],ignore_index=True)\n",
    "\n",
    "datareal30_train = {'Pessoa':labels_train,'Imagem':f30r_train}\n",
    "real30_train = pd.DataFrame(data=datareal30_train)\n",
    "datareal30_test = {'Pessoa':labels_test,'Imagem':f30r_test}\n",
    "real30_test = pd.DataFrame(data=datareal30_test)\n",
    "                  \n",
    "dataimag30_train = {'Pessoa':labels_train,'Imagem':f30i_train}\n",
    "imag30_train = pd.DataFrame(data=dataimag30_train)\n",
    "dataimag30_test = {'Pessoa':labels_test,'Imagem':f30i_test}\n",
    "imag30_test = pd.DataFrame(data=dataimag30_test)\n",
    "                  \n",
    "datari30_train = {'Pessoa':labels_train,'Imagem':f30ri_train}\n",
    "ri30_train = pd.DataFrame(data=datari30_train)\n",
    "datari30_test = {'Pessoa':labels_test,'Imagem':f30ri_test}\n",
    "ri30_test = pd.DataFrame(data=datari30_test)\n",
    "\n",
    "aux30_train = [np.concatenate((real30_train['Imagem'][n],imag30_train['Imagem'][n])) for n in range(360)]\n",
    "datafull30_train = {'Pessoa':labels_train,'Imagem':aux30_train}\n",
    "full30_train = pd.DataFrame(data=datafull30_train)\n",
    "aux30_test = [np.concatenate((real30_test['Imagem'][n],imag30_test['Imagem'][n])) for n in range(40)]\n",
    "datafull30_test = {'Pessoa':labels_test,'Imagem':aux30_test}\n",
    "full30_test = pd.DataFrame(data=datafull30_test)\n",
    "\n",
    "conc30_train = pd.concat([real30_train,imag30_train],ignore_index=True)\n",
    "conc30_test = pd.concat([real30_test, imag30_test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Configuração e uso do KNN\n",
    "Estamos utilizando a ferramenta *scikit-learn* para executar o KNN, a métrica de distância utilizada é a distância euclidiana que é calculada pela própria função do *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo classificador\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1,metric='euclidean')\n",
    "\n",
    "#treinando o classficador e gerando resultados\n",
    "knn.fit(list(real2_train['Imagem']),real2_train['Pessoa'])\n",
    "resultr2 = knn.predict(list(real2_test['Imagem']))\n",
    "\n",
    "knn.fit(list(imag2_train['Imagem']),imag2_train['Pessoa'])\n",
    "resulti2 = knn.predict(list(imag2_test['Imagem']))\n",
    "\n",
    "knn.fit(list(ri2_train['Imagem']),ri2_train['Pessoa'])\n",
    "resultri2 = knn.predict(list(ri2_test['Imagem']))\n",
    "\n",
    "knn.fit(list(full2_train['Imagem']),full2_train['Pessoa'])\n",
    "resultfull2 = knn.predict(list(full2_test['Imagem']))\n",
    "\n",
    "knn.fit(list(conc2_train['Imagem']),conc2_train['Pessoa'])\n",
    "resultconc2 = knn.predict(list(conc2_test['Imagem']))\n",
    "\n",
    "knn.fit(list(real50_train['Imagem']),real50_train['Pessoa'])\n",
    "resultr50 = knn.predict(list(real50_test['Imagem']))\n",
    "\n",
    "knn.fit(list(imag50_train['Imagem']),imag50_train['Pessoa'])\n",
    "resulti50 = knn.predict(list(imag50_test['Imagem']))\n",
    "\n",
    "knn.fit(list(ri50_train['Imagem']),ri50_train['Pessoa'])\n",
    "resultri50 = knn.predict(list(ri50_test['Imagem']))\n",
    "\n",
    "knn.fit(list(full50_train['Imagem']),full50_train['Pessoa'])\n",
    "resultfull50 = knn.predict(list(full50_test['Imagem']))\n",
    "\n",
    "knn.fit(list(conc50_train['Imagem']),conc50_train['Pessoa'])\n",
    "resultconc50 = knn.predict(list(conc50_test['Imagem']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo classificador\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1,metric='euclidean')\n",
    "\n",
    "#treinando o classficador e gerando resultados\n",
    "knn.fit(list(real20_train['Imagem']),real20_train['Pessoa'])\n",
    "resultr20 = knn.predict(list(real20_test['Imagem']))\n",
    "\n",
    "knn.fit(list(imag20_train['Imagem']),imag20_train['Pessoa'])\n",
    "resulti20 = knn.predict(list(imag20_test['Imagem']))\n",
    "\n",
    "knn.fit(list(ri20_train['Imagem']),ri20_train['Pessoa'])\n",
    "resultri20 = knn.predict(list(ri20_test['Imagem']))\n",
    "\n",
    "knn.fit(list(full20_train['Imagem']),full20_train['Pessoa'])\n",
    "resultfull20 = knn.predict(list(full20_test['Imagem']))\n",
    "\n",
    "knn.fit(list(conc20_train['Imagem']),conc20_train['Pessoa'])\n",
    "resultconc20 = knn.predict(list(conc20_test['Imagem']))\n",
    "\n",
    "knn.fit(list(real30_train['Imagem']),real30_train['Pessoa'])\n",
    "resultr30 = knn.predict(list(real30_test['Imagem']))\n",
    "\n",
    "knn.fit(list(imag30_train['Imagem']),imag30_train['Pessoa'])\n",
    "resulti30 = knn.predict(list(imag30_test['Imagem']))\n",
    "\n",
    "knn.fit(list(ri30_train['Imagem']),ri30_train['Pessoa'])\n",
    "resultri30 = knn.predict(list(ri30_test['Imagem']))\n",
    "\n",
    "knn.fit(list(full30_train['Imagem']),full30_train['Pessoa'])\n",
    "resultfull30 = knn.predict(list(full30_test['Imagem']))\n",
    "\n",
    "knn.fit(list(conc30_train['Imagem']),conc30_train['Pessoa'])\n",
    "resultconc30 = knn.predict(list(conc30_test['Imagem']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Resultados\n",
    "### 3.1 Matriz 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apenas parte real: 0.0 %\n",
      "Apenas parte imaginária: 10.0 %\n",
      "Parte real e imaginária, combinando módulos: 5.0 %\n",
      "Parte real e imaginária, somando distâncias: 7.5 %\n",
      "Parte real e imaginária, como imagens distintas: 5.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Apenas parte real:',accuracy_score(real2_test['Pessoa'],resultr2)*100,'%')\n",
    "print('Apenas parte imaginária:',accuracy_score(imag2_test['Pessoa'],resulti2)*100,'%')\n",
    "print('Parte real e imaginária, combinando módulos:',accuracy_score(ri2_test['Pessoa'],resultri2)*100,'%')\n",
    "print('Parte real e imaginária, somando distâncias:',accuracy_score(full2_test['Pessoa'],resultfull2)*100,'%')\n",
    "print('Parte real e imaginária, como imagens distintas:',accuracy_score(conc2_test['Pessoa'],resultconc2)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Matriz 20x20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apenas parte real: 85.0 %\n",
      "Apenas parte imaginária: 92.5 %\n",
      "Parte real e imaginária, combinando módulos: 85.0 %\n",
      "Parte real e imaginária, somando distâncias: 90.0 %\n",
      "Parte real e imaginária, como imagens distintas: 88.75 %\n"
     ]
    }
   ],
   "source": [
    "print('Apenas parte real:',accuracy_score(real20_test['Pessoa'],resultr20)*100,'%')\n",
    "print('Apenas parte imaginária:',accuracy_score(imag20_test['Pessoa'],resulti20)*100,'%')\n",
    "print('Parte real e imaginária, combinando módulos:',accuracy_score(ri20_test['Pessoa'],resultri20)*100,'%')\n",
    "print('Parte real e imaginária, somando distâncias:',accuracy_score(full20_test['Pessoa'],resultfull20)*100,'%')\n",
    "print('Parte real e imaginária, como imagens distintas:',accuracy_score(conc20_test['Pessoa'],resultconc20)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Matriz 30x30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apenas parte real: 92.5 %\n",
      "Apenas parte imaginária: 92.5 %\n",
      "Parte real e imaginária, combinando módulos: 95.0 %\n",
      "Parte real e imaginária, somando distâncias: 95.0 %\n",
      "Parte real e imaginária, como imagens distintas: 92.5 %\n"
     ]
    }
   ],
   "source": [
    "print('Apenas parte real:',accuracy_score(real30_test['Pessoa'],resultr30)*100,'%')\n",
    "print('Apenas parte imaginária:',accuracy_score(imag30_test['Pessoa'],resulti30)*100,'%')\n",
    "print('Parte real e imaginária, combinando módulos:',accuracy_score(ri30_test['Pessoa'],resultri30)*100,'%')\n",
    "print('Parte real e imaginária, somando distâncias:',accuracy_score(full30_test['Pessoa'],resultfull30)*100,'%')\n",
    "print('Parte real e imaginária, como imagens distintas:',accuracy_score(conc30_test['Pessoa'],resultconc30)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Matriz 50x50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apenas parte real: 92.5 %\n",
      "Apenas parte imaginária: 90.0 %\n",
      "Parte real e imaginária, combinando módulos: 92.5 %\n",
      "Parte real e imaginária, somando distâncias: 92.5 %\n",
      "Parte real e imaginária, como imagens distintas: 91.25 %\n"
     ]
    }
   ],
   "source": [
    "print('Apenas parte real:',accuracy_score(real50_test['Pessoa'],resultr50)*100,'%')\n",
    "print('Apenas parte imaginária:',accuracy_score(imag50_test['Pessoa'],resulti50)*100,'%')\n",
    "print('Parte real e imaginária, combinando módulos:',accuracy_score(ri50_test['Pessoa'],resultri50)*100,'%')\n",
    "print('Parte real e imaginária, somando distâncias:',accuracy_score(full50_test['Pessoa'],resultfull50)*100,'%')\n",
    "print('Parte real e imaginária, como imagens distintas:',accuracy_score(conc50_test['Pessoa'],resultconc50)*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
